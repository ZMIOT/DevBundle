\section{Introduction}
\label{sec:intro}
In many researches and applications of indoor scenes, the data of segmented and even annotated 3D indoor scenes are required as either database or training data (e.g.\cite{SearchClassify}\cite{SceneFromExample}\cite{Fisher:2012:ESO:2366145.2366154}\cite{Chen:2014:ASM:2661229.2661239}\cite{Fisher:ActivityCentricSceneSynthesis}).\\
One way to build such database is to interactively compose scenes from 3D shape models, resulting in scenes with object segmentation and annotation naturally available. Another way is to mannually segment and annotate existing scenes. This procedure can be tedious and time consuming, despite the efforts to improve the interaction experience (e.g.\cite{Merrell:2011:IFL:2010324.1964982}\cite{Xu:2013:SSC:2461912.2461968}).\\
A better way would is to automatically generate scenes from 3D shape models according to the input RGB or RGB-D images (e.g.\cite{Liu2015Model}\cite{Chen:2014:ASM:2661229.2661239}). In such methods, a retrievial procedure is usually needed and inevitablely limits the result to a certain set of 3D models despite the actual 3D model in the input images.\\
We prefer an approach that helps us build such dataset directly from the captured data. One of the major gap between the required dataset and available scene capturing framework (e.g.\cite{KinectFusion}) is the general object level segmentation. We want to stress that a general object level segmentation problem should not be treated as an equivalence of multilabel classification problem since it is not limited to a certain set of objects. For 3D data, \cite{3DReasoningfromBlockstoStability} uses some simplified physical prior knowledge (i.e. the block-based stability) to help achieving the general objectness segmentation. The work of \cite{Xu:2015:ACS:2816795.2818075} proposes a practical and rather complete framework to close the gap between the required dataset and available scene capturing method. One of the observations in \cite{Xu:2015:ACS:2816795.2818075} is that the motion consistency of rigid object can serve as a strong evidence of general objectness. To exploit this fact, they employ a robot to do proactive push and use the movement tracking to verify and iteratively improve their object level segmentation result. Our work presented in this paper is trying to exploit the same observation from a different approach.\\
We intend to use the motion consistency in objects that is naturally revealed by human activities along the time. Down to this approach, we are facing the choice of scanning schemes. One way is to record the change of the scene along with the human activities, another is to  schedule a daily sweep to only record the result of human activities but avoid the instant of human motion. The main challenge brought in by the second scheme is that we may not be able to solve the object correspondence by a local search due to the sparse sampling over time. The very same challenge also exists in the first scheme due to the exclusion caused by human bodies not to mention other additional process (e.g. tracking with severe occlussion ) needed for human bodies. Therefore, we choose the second scheme. With the second scanning scheme, our original intention of building 3D scene dataset from capturing leads us to the problem of coupled joint registration and co-segmentation.\\ 
In this problem, registration and segmentaion are entangled in each other. On one hand the segmentation depends on the registration to connect the point clouds into series of rigid movement so that the objectness segmentation can be done based on the motion consistency. On the other hand, the registration depends on the segmentation to break the problem into a series of rigid joint registration instead of a joint registration with non-coherent point drift. The non-coherent point drift means that a pair of points is close to each other in one point set but their correspondent pair of points in another point set is far from each other, in other words, the point drift of this pair is non-coherent. This happens when this pair of points actually belong to different objects.\\
To model the problem, we employ several groups of Gaussian models and each group of these Gaussian models represents a potential object. This model unentangle the registration and segmentation in the way that the segmentation can be done by evaluating the probability of points belongs to the Gaussian mixture models and the registration can be done by estimating rigid registration against each gaussain mixture models.\\
In summary our work makes following contributions: \\
%
%"We are the first solution that can be downloaded to a phone," Tawkon co-founder and CEO Gil Friedlander told Reuters
%
1) As far as we know, we are the first work that bring up with the problem of point set joint registration and co-segmentation for indoor scenes.\\
2) We come up with a Gaussian mixture model based formulation to simultaneously model both the joint registration and co-segmentation problem.\\
3) Targeting the disadvantages of our formulation, we design a procedure of interaction and provide a practical tool for point set joint registration and co-segmentation based on it. We will release our tool with acceptance of this paper.
