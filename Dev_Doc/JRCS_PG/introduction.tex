\section{Introduction}
\label{sec:intro}
In many researches and applications of indoor scenes the data of segmented and even annotated 3D indoor scenes are required as either data base or training data (e.g.\cite{SearchClassify}\cite{SceneFromExample}\cite{Fisher:2012:ESO:2366145.2366154}\cite{Chen:2014:ASM:2661229.2661239}\cite{Fisher:ActivityCentricSceneSynthesis}).\\
One way to build such database is to interactively compose scenes from 3D shape models resulting in scenes with object segmentation and annotation naturally available, or to mannually segment and annotate existing scenes. This procedure can be tedious and time consuming, despite the efforts to improve the interaction experience(e.g.\cite{Merrell:2011:IFL:2010324.1964982}\cite{Xu:2013:SSC:2461912.2461968}).\\
Another way is to automatically generate scenes from 3D shape models according to the input RGB or RGB-D images(e.g.\cite{Liu2015Model}\cite{Chen:2014:ASM:2661229.2661239}). In such methods, a retrievial procedure is usually needed and inevitablely limit the result to a certain set of 3D models despite the actual 3D model in the input images.\\
We prefer an approach that helps us build such dataset directly from the captured data. One of the major gap between the required data set and available scene capturing framework (e.g.\cite{KinectFusion}) is the general object level segmentation. We want to stress that a general object level segmentation problem should not be treated as an equivalence of multilabel classification problem since it is not limited to a certain set of objects. For 3D data, \cite{3DReasoningfromBlockstoStability} used some simplified physical prior knowledge (i.e. the block-based stability) to help acheiving the general objectness segmentation, while the work of \cite{Xu:2015:ACS:2816795.2818075} proposes a practical and rather complete framework to close the gap between the required data set and available scene capturing method. One of the observation in \cite{Xu:2015:ACS:2816795.2818075} is that the motion consistency of rigid object can serve as a strong evidence of general objectness. To exploit this fact, they employ a robot to do proactive push and use the movement tracking to verify and iteratively improve their object level segmentation result. Our work presented in this paper is trying to exploit the same observation from a different approach.\\
We intend to use the motion consistency in objects that is naturally revealed by human activities along the time. Down to this approach, we are facing the choice of scanning scheme. One way is to record the change of the scene along with the human activities, another is to  schedule a daily or even a once every half day sweep to only record the result of human activities but avoid the instant of human motion. The main challenge brought in by the second scheme is that we may not be able to solve the object correspondence by a local search due to the sparse sampling over time, but the very same challenge exists in the first scheme due to the exclusion caused by human bodies not to mention other additional process(e.g. tracking with severe oclussion ) needed for human bodies. With the second scanning scheme, our original intention of building 3D scene data set from capturing naturally leads us to the problem of coupled joint registration and co-segmentation.\\ 
In this problem, registration and segmentaion are entangled in each other. On one hand the segmentation depends on the registration to connect the point clouds into series of rigid movement so that the objectness segmentation can be done based on the motion consistency, on the other hand, the registration depends on the segmentation to break the problem into a series of rigid joint registration instead of a joint registration with non-coherent point drift(A pair of points is close to each other in one point set but their correspondent pair of points in another point set is far from each other, in other words, the point drift of this pair is non-coherent. (This happens when this pair of points actually belong to different objects.)\\
To model the problem, we employ a group of Gaussian mixture models and each of these Gaussian mixture models represents a potential object. This model unentangle the registration and segmentation in the way that the segmentation can be done by evaluate the probability of points belongs to the Gaussian mixture models and the registration can be done by evaluate rigid registration against each gaussain mixture models.\\
In summary our work makes following contributions: \\
Firstly, as far as we know we are the first work that bring up with the problem of point set joint registration and co-segmentation for indoor scenes.\\
Secondly, we come up with a Gaussian mixture model based formulation to simultaneously model both the joint registration and co-segmentation problem.\\
Thirdly, targeting the disadvantages of our formulation, we design a procedure of interaction and provide a practical tool for point set joint registration and co-segmentation based on it. We will release our tool with acceptance of this paper.
