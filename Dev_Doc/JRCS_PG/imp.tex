\section{Initialization and Optimization}
\label{sec:imp}


Based on our formulation in Sec.~\ref{sec:method}, our algorithm can be summarized as in Algorithm \ref{alg:jrcs}.
%
In this section, we explain how do we initialize the parameters and guide the optimization with user interactions for our algorithm.

\begin{algorithm}[htb]
	\caption{Joint Registration and Co-segmentation (JRCS)}
	\label{alg:jrcs}
	\textbf{Input:}~~\\  
	$\{\vb{V}_m\}$: $M$ 3D point sets\\
	$\Theta^0$: Initial parameters\\
	$\{\beta_{ik}\}_{m}$: Layout prior\\
	\textbf{Output:}~~\\
	$\Theta^q$: Final parameters~~
	\begin{enumerate}
		\item $q\leftarrow1$
		\item \textbf{repeat}
		\item E-step: Use $\Theta^{q-1}$ to estimate $\alpha_{mik}^q$ according to Eq.~(\ref{equ:estep}) (use Eq.~(\ref{equ:bestep}) for the bilateral formulation);
		\item \textbf{if} $q < q_{alt}$ \textbf{then} Alter $\alpha_{mik}^q$ with $\{\beta_{ik}\}_{m}$ according to Eq.~(\ref{equ:alteralpha});
		\item M-step-a: use $\alpha^q_{mik}$, $\mathbf x^{q-1}_k$ to estimate $\{\mathbf{R}_{mn}^q\}$ and $\{\mathbf t_{mn}^q\}$ according to Eqs.~(\ref{equ:updateR})(\ref{equ:updatet});
		\item M-step-b: use $\alpha^q_{mik}$, $\{\mathbf{R}_{mn}^q\}$ and $\{\mathbf{t}_{mn}^q\}$ to update other parameters for Gaussian models according to Eqs.~(\ref{equ:updatexk})(\ref{equ:updatesigma})(\ref{equ:updatepk})(\ref{equ:updatey})  (or Eqs.~(\ref{equ:updatefk})(\ref{equ:updatefsigma}) for the bilateral formulation);
		\item $q \leftarrow q+1$
		\item \textbf{until} $q > q_{max}$
		\item \textbf{return} $\Theta^q$
	\end{enumerate}
\end{algorithm}



\subsection{Initialization}
\label{sec:imp:interact}
%
In our formulation, there are a large number of parameters that can not be easily initialized.
%
We provide an interactive tool to help with the initialization, as shown in Figure~\ref{fig:interact}. 
A set of boxes can be manually placed to indicate a rough segmentation of different objects in one point set.
%User can use boxes with different colors to indicate a scene layout for different objects in one of the point sets.
%
Based on the roughly placed boxes, we can initialize the parameters in our formulation. 

\noindent\textbf{Number of objects $N$}: $N$ is naturally determined as the number of placed boxes in the point set.
%
\noindent\textbf{Number of Gaussian models in each object $\{K_n\}^N_{n=1}$}: While objects in an indoor scene have varying volumes, we use different number of Gaussian models for objects according to their volumes. We set $K_n$ as 
\begin{equation}
\label{equ:K_n}
K_n=\frac{V_n}{\sum V_n}K_{all},
\end{equation}
%
where $V_n$ represents the total volume of the boxes in the $n^{th}$ color. 
The total number of Gaussian models in the scene is initialized as $K_{all}=\frac{median(\{L_m\}^M_{m=1}}{2}$, where $L_m$ is the point number of the $m$th input point sets. 
This is an empirical choice borrowed from \cite{Evangelidis2014}.

\begin{figure}
	\centering
	\includegraphics[width=.3\linewidth]{images/interact01.png}
	\includegraphics[width=.3\linewidth]{images/interact02.png}
	\includegraphics[width=.3\linewidth]{images/interact03.png}
	\includegraphics[width=.3\linewidth]{images/interact04.png}
	\includegraphics[width=.3\linewidth]{images/interact05.png}
	\includegraphics[width=.3\linewidth]{images/interact06.png}
	\caption{\label{fig:interact}
		From the first to the sixth, the nine \cxj{nine or six?} images show the procedure of interaction:
		the user picks one point set and place boxes to indicate the layout for this point set. The box in white is the box currently under editing. The boxes in other colors are boxes placed to represent object layouts. One color represents one object. The interaction allows multiple boxes to represents same object.(e.g. the desk is represented by three boxes in same color) \cxj{I suggest only use three images here.}}
\end{figure}


\noindent\textbf{Gaussian Parameters $\{p_k,\mathbf{x}_k,\Sigma_k\}_{k=1}^{K_{all}}$}:
We then set $p_k=\frac{1}{K_{all}}$ as the initial values for $p_k$, which means each Gaussian has the same weight at the beginning. 
%
For the Gaussian centroids $\{\mathbf{x}_k\}$, we first allocate memory for total $K_{all}$ Gaussian centroids and then separate them into $N$ groups to represent $N$ objects. 
%Each group has $K_n$ Gaussian centroids based on Eq.~(\ref{equ:K_n}). We implement this by recording the start and end indices of the $N$ objects. In other words, we record $\{0,K_1,K_1+1,K_1+K_2,...,K_S+1,K_S+K_n,...\}$. 
For the $n^{th}$ object, we initialize its $K_n$ Gaussian centroids $\{\mathbf{x}_k\}_{K_S+1}^{K_S+K_n}$ as random positions uniformly distributed on the surface of a sphere, whose radius $r$ is chosen as the median of the radius of the input point sets. 
\cxj{confusing here..}
%
The center of the $n^{th}$ sphere is $\mathbf{c}_n=(0,0,z_n)$, where $z_n\in \{-(N-1)r,-(N-3)r,...,(N-1)r\}$.
\cxj{I modified here? $z_n=\frac{2n+1-N}{N}r$} 
%
This means that the object models are vertically arranged in latent space as shown in Figure~\ref{fig:teaser}(c). 
%
We choose vertical arrangement for groups of object merely for the convenience of visualization.
%
Figure~\ref{fig:iter}(a) \cxj{add subfigure no.} shows the initial Gaussian centroids of a scene.
%
The variance $\{Sigma_k\}$ are all initialized as $\Sigma_k=\sigma^2 \vb{I}$ in which $\sigma=r$.
%The $r$ here is the radius of sphere. 
Without any prior knowledge, such initialization for Gaussian parameters put all the objects at similar starting points and they can compete fairly to group points in the input point sets.   

\noindent\textbf{Transformations} $\{\phi_{mn}\}_{m=1,n=1}^{M,N}=\{\mathbf{R}_{mn},\mathbf{t}_{mn}\}_{m=1,n=1}^{M,N}$:
Since we have chosen spheres as the initial shapes, we can initialize all the $\mathbf{R}_{mn}$ to the identity matrix.
%
%For sphere, the different initial orientation makes little differences.
%
For translations, we initialize them as $\mathbf{t}_{mn}=- \mathbf{c}_n$ so that all the object models start with position at the origin point when they are transformed to the space of each input set. 
%
However, if boxes are manually placed in the $m^{th}$ input point set, we treat the associated $\mathbf{t}_{mn}$ differently:
%
\begin{equation}
	\label{equ:initt}
	\vb{t}_{mn}=\frac{\sum_{\vb{v}_{mi} \in B_n}\vb{v}_{mi}}{N(B_n)}-\vb{c}_n, 
\end{equation}
where $N(B_n)$ here is the number of elements in the point set that is enclosed by the manually placed boxes indicating the $n^{th}$ object.


\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{images/localoptimal/localoptimal}
	\caption{\label{fig:localoptimal} An example result when our algorithm converges to a local optimal. (a) The segmentation result in six point sets of this local optimal. (b) The Gaussian centroids of the latent object models. It shows that the chair and the table are not perfectly segmented. \cxj{remove ... in the figure.}}
\end{figure}



\subsection{Layout Constrained Optimization}
\label{subsec:optimzation}

The expectation maximization framework is easily converged to a local optimal. 
\cxj{I move fig 4 here.}
\mdf{From a random initialization for object models, the EM framework usually converges to a local optimal, as shown in Figure~\ref{fig:localoptimal}. It shows that the chair and the table are not perfectly segmented. }
%
To cope with this problem, we adopt the user placed boxes as soft constraints to guide the optimization and confine the shape of generated object models. 
Such constraints are enforced by altering the posterior probability as
\begin{equation}
	\label{equ:alteralpha}
	\alpha_{mik}^*=\frac{\alpha_{mik}\beta_{mik}}{\sum_{i,k}\alpha_{mik}\beta_{mik}}
\end{equation}
%
where $\beta_{mik}$ is the prior probability according to the boxes, defined as:
\begin{equation}
	\beta_{mik}=\left\{
	\begin{array}{lcl}
		1,& &\mathbf v_{mi} \in B_n\\
		\exp(-\frac{\min_{\mathbf v_{mj}}|| \mathbf v_{mi} - \mathbf v_{mj} ||_2^2  )}{L}),& &\mathbf v_{mi} \notin B_n~and~\mathbf v_{mj} \in B_n\\
	\end{array} \right.
\end{equation}
%
\cxj{So $\beta_{mik}$ are not related with $k$?}
where $B_n$ is a set of points that are enclosed by the boxes used to represent object $O_{n}$. 
%
%The $k^{th}$ Gaussian model is predefined to be one of the Gaussians used to represent $n^{th}$ object.
$\min_{\vb{v}_{mj}}|| \vb{v}_{mi} - \vb{v}_{mj} ||_2^2$ is the minimum distance from a point $\vb{v}_{mi}$ to the points $\{\vb{v}_{mj}\}$ in an object $O_n$.
%the squared Euclidean distance from point $v_{mi}$ to the point set $B_n$, as we define the distance from a point to a point set as the minimum distance from the point to any point inside the point set. 
$L$ here is a constant number with $L=2r^2$, and $r$ is the median of the radius of input point sets. \cxj{$L$, $r$ are used many times for different things?}
%
The radius of a point set is half of length of diagonal line of its axis-aligned bounding box.   
%
This alteration on posterior probability is only done with the points in the $m^{th}$ point set where boxes are manually placed. 
%



\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{images/Initialization/iters}
	\caption{\label{fig:iter} This figure shows an example of our algorithm converging with increasing number of iterations. The $1^{st}-3^{rd}$ row show the images for three example out of total nine point sets. The $4^{th}$ row shows the images for Gaussian centroids (the space of object models). The first column shows the input layout (boxes) which is only placed in the first point set. The second column shows the input point sets and the initial Gaussian centroids. The $3^{rd}-9^{th}$ shows result of segmentation (in $1^{st}-3^{rd}$ row) and Gaussian centroids (in $4^{th}$ row) at different iteration numbers $q$. The $q$ is shown at top of each column}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{images/Initialization/obj_iter.png}
	\caption{\label{fig:iter_curve}This figure shows the curve of objective function - iteration number for the data partially shown in Figure~\ref{fig:iter}. The objective value is calculated according to (\ref{equ:obj3}). Note that the curve is not monotonic increasing, which makes it difficult to set a stop condition based on our objective.}
\end{figure}

This alteration can prevent the object models from deforming into an arbitrary shape.
%
%In Figure~\ref{fig:localoptimal}, the $2nd$ and $3rd$ object has deformed into a combination of two objects due to lack of constraint.
%
Figure~\ref{fig:iter} and Figure~\ref{fig:iter_curve} demonstrate an example of converging procedure with the box constraints. 
%
\mdf{We can see that with the boxes placed in one point set as constraints, our framework converges to a good segmenation result. The point sets are finally segmented to three objects, and the object models develop from a initial sphere shape at $q=1$ to a dense point cloud which fits the input point sets well. }
%
However, in Figure~\ref{fig:iter_curve}, the objective function is not monotonically increasing. 
This is due to our alteration on the posterior probability in Eq.~(\ref{equ:alteralpha}). This alteration is a quite brutal solution to enforce the shape constraint and it will interfere with the convergence of EM algorithms.
% 
This makes it difficult to set a stop criteria based on the objective value. 
We now stop the iteration when the maximum iteration number $q_{max}$ is reached.
% as shown in Algorithm~\ref{alg:jrcs} step 8. 
In Figure~\ref{fig:iter}, note that the segmentation in the first point set seldom changes until the last few iterations. 
\cxj{Zoom in the bear and table part in the first row.}
%
This is due to the alteration in (\ref{equ:alteralpha}) as well. 
%
In order to constrain the object shape, we do alteration on the posterior probability of first point set based on the boxes in it. This alteration is only done in $q_{alt}$ iterations as shown in Algorithm~\ref{alg:jrcs} step 4. 
However, the initial segmentation based on the boxes is not accurate. 
Therefore, we no longer do such alteration in the last few iterations and let the algorithm to refine the segmentation in first point set based on the result of registration. 
We set $q_{alt}=q_{max}-10$ for all experiments in this paper.

For initialization and object shape constraint, the boxes are first roughly placed in one point set only. 
However, in more challenging cases, our algorithm will stuck at local minimum due to objects' non-local movement. 
For such cases, our implementation allows placing more constraints in other point sets (even during the optimization process). 
The same alteration as (\ref{equ:alteralpha}) is performed to further constrain the optimization. We will discuss an example of such case later in Sec~\ref{subsec:interact}.

\cxj{I suggest put Fig 5, 6 together.}